### MAKEFILE TARGETS

function dl-install-lima { #
  # ./lima/01-install-lima.sh

  arch=$(uname -m)
  
  read -p "enter Lima version to install: " VERSION
  
  curl -L -O https://github.com/lima-vm/lima/releases/download/v${VERSION}/lima-${VERSION}-Darwin-${arch}.tar.gz
  tar xvfz lima-${VERSION}-Darwin-${arch}.tar.gz
  echo "version ${VERSION} installed under ./bin"
  
  ./bin/limactl --version
}

function echo-lima-instance { #
  echo ${LIMA_INSTANCE}
}

function create { #
  # ./lima/02-lima-create.sh

  echo "Using limactl version: "
  ${LIMACTL_BIN} --version

  # limactl start ./03-docker.yaml
  ${LIMACTL_BIN} start ./lima/${LIMA_INSTANCE}.yaml --tty=false --name ${LIMA_INSTANCE}
}

function delete { #
  # ./lima/95-lima-delete.sh

  ${LIMACTL_BIN} delete ${LIMA_INSTANCE}
}

function start { #
  # ./lima/10-lima-start.sh;

  ${LIMACTL_BIN} start ${LIMA_INSTANCE}
  echo "now run: make config-network-end-to-end"
}

function stop { #
  # ./lima/91-lima-stop.sh

  ${LIMACTL_BIN} stop ${LIMA_INSTANCE}
}

function shell { #
  # ./lima/12-lima-shell.sh

  ${LIMACTL_BIN} shell ${LIMA_INSTANCE}
}

function clear-obsolete-kind-context { #
  @read -p "enter kind context to delete: " CONTEXT
  kubectl config delete-context $$CONTEXT
  kubectl config delete-cluster $$CONTEXT
  kubectl config delete-user $$CONTEXT
}

function kind-create { # num name region zone
  # @./kind/20-kind-create.sh $(filter-out $@,$(MAKECMDGOALS))

  NUM=$1
  NAME=$2

  # USAGE
  if [ -z "$1" -o -z "$2" ]; then
    echo "Usage: $0 <KinD instance number> <kind cluster name>"
    exit 1
  fi

  # VARS
  if [ "$#" -lt 3 ]; then
    REGION=us-east
  elif [ -z "$3" ]; then
    REGION=us-east
  else
    REGION=$3
  fi

  if [ "$#" -lt 4 ]; then
    ZONE=us-east-b
  elif [ -z "$4" ]; then
    ZONE=us-east-b
  else
    ZONE=$4
  fi

  TWO_DIGITS=$(printf "%02d\n" ${NUM})
  mkdir -p $KIND_HOST_HOME_DIR
  CLUSTER_CONFIG_FILE=${KIND_HOST_HOME_DIR}/$NAME.yaml
  METALLB_CONFIG_FILE=${KIND_HOST_HOME_DIR}/$NAME-metallb.yaml

  # PREP
  rm -v ${CLUSTER_CONFIG_FILE} || true
  rm -v ${METALLB_CONFIG_FILE} || true

  # KIND CLUSTER with CONTAINERD PATCHES
  cat << EOF > ${CLUSTER_CONFIG_FILE}
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: ${NAME}
# featureGates:
#   "TokenRequest": true
#   "EphemeralContainers": true
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 6443
    hostPort: 70${TWO_DIGITS}
networking:
  serviceSubnet: "10.${NUM}.0.0/16"
  podSubnet: "10.1${NUM}.0.0/16"
kubeadmConfigPatches:
- |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true,topology.kubernetes.io/region=${REGION},topology.kubernetes.io/zone=${ZONE}"
containerdConfigPatches:
- |-
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
    endpoint = ["http://${DOCKERIO_CACHE_NAME}:${DOCKERIO_CACHE_PORT}"]
  [plugins."io.containerd.grpc.v1.cri".registry.configs."docker.io".tls]
    insecure_skip_verify = true
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."quay.io"]
    endpoint = ["http://${QUAYIO_CACHE_NAME}:${QUAYIO_CACHE_PORT}"]
  [plugins."io.containerd.grpc.v1.cri".registry.configs."quay.io".tls]
    insecure_skip_verify = true
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."gcr.io"]
    endpoint = ["http://${GCRIO_CACHE_NAME}:${GCRIO_CACHE_PORT}"]
  [plugins."io.containerd.grpc.v1.cri".registry.configs."gcr.io".tls]
    insecure_skip_verify = true
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."us-docker.pkg.dev"]
    endpoint = ["http://${USDOCKERPKGDEV_CACHE_NAME}:${USDOCKERPKGDEV_CACHE_PORT}"]
  [plugins."io.containerd.grpc.v1.cri".registry.configs."us-docker.pkg.dev".tls]
    insecure_skip_verify = true
EOF

  # KinD image
  kind_img_loaded=$(docker image ls --format '{{.Repository}}:{{.Tag}}' | grep "kindest/node:${KIND_NODE_VERSION}" | wc -l)
  if [ ${kind_img_loaded} -ne 1 ]; then
    echo "Loading the KinD node image to the VM..."
    docker load < ${LIMA_DATA_DIR}/kind-${KIND_NODE_VERSION}-image.tar
  fi

  # KinD cluster
  echo "Creating the KinD cluster with name ${NAME}"
  #kind create cluster -q --config=${CLUSTER_CONFIG_FILE} --image kindest/node:${KIND_NODE_VERSION} --retain || true
  kind create cluster --config=${CLUSTER_CONFIG_FILE} --image kindest/node:${KIND_NODE_VERSION} --retain || true
  #kind export logs --name ${NAME}; kind delete cluster
  kind export logs --name ${NAME}
  echo "KinD cluster creation complete!"

  export CONTEXT_NAME="kind-${NAME}"

  # METALLB
  echo "Loading the MetalLB images to the KinD node"
  kind load image-archive ${LIMA_DATA_DIR}/quay.io-metallb-controller-v0.11.0.tar --name ${NAME}
  kind load image-archive ${LIMA_DATA_DIR}/quay.io-metallb-speaker-v0.11.0.tar --name ${NAME}

  echo "Installing MetalLB"
  kubectl --context ${CONTEXT_NAME} apply -f ${HOST_WORKDIR}/metallb/namespace.yaml
  kubectl --context ${CONTEXT_NAME} create secret generic -n metallb-system memberlist --from-literal=secretkey="$(openssl rand -base64 128)" 
  kubectl --context ${CONTEXT_NAME} apply -f ${HOST_WORKDIR}/metallb/metallb.yaml
  sleep 5
  # kubectl --context ${CONTEXT_NAME} -n metallb-system wait po --for condition=Ready --timeout -1s --all

  SUBNET_PREFIX=$(docker network inspect kind | jq -r '.[0].IPAM.Config[0].Subnet' | awk -F. '{print $1"."$2}')

  cat << EOF > ${METALLB_CONFIG_FILE}
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: metallb-system
  name: config
data:
  config: |
    address-pools:
    - name: default
      protocol: layer2
      addresses:
      - ${SUBNET_PREFIX}.${NUM}.1-${SUBNET_PREFIX}.${NUM}.254
EOF

  kubectl --context ${CONTEXT_NAME} apply -f ${METALLB_CONFIG_FILE}

  # Registries
  echo "Configuring image registry mirrors"
  # exec ${LIMA_WORKDIR}/lima/17-docker-registries.sh
  registries
  echo "Registries configured and attached to local Kind bridge"

  echo "End of script"
}

function kind-create-triple { #
  # @./kind/22-kind-create-triple.sh

  time kind-create 1 1-mgmt &
  time kind-create 2 2-cluster1 &
  time kind-create 3 3-cluster2 &
}

function kind-create-three { #
  kind-create-triple
}

function kind-delete { # clustername
  # @./kind/90-kind-delete.sh $(filter-out $@,$(MAKECMDGOALS))

  if [ -z "$1" ]; then
    echo "Usage: $0 <KinD cluster name>"
    exit 1
  fi

  # test if $1 is a valid kind cluster
  if ! kind get clusters | grep -q $1; then
    echo "ERROR: $1 is not a valid KinD cluster"
    exit 1
  fi
}

function kind-delete-all { #
  # @./kind/93-kind-delete-all.sh

  # for each kind cluster, delete it
  for cluster in $(kind get clusters); do
    kind delete cluster --name $cluster
  done
}

function list-machines { #
  ./bin/limactl list
}

function list-kind-clusters { #
  kind get clusters
}

function kind-list { #
  list-kind-clusters
}

function setup-kind-bridge { #
  # ./kind/19-kind-bridge.sh

  echo "Creating the 'kind' docker network, type bridge"
  docker network create \
      -d=bridge \
      --scope=local \
      --attachable=false \
      --gateway=172.18.0.1 \
      --ingress=false \
      --internal=false \
      --subnet=172.18.0.0/16 \
      -o "com.docker.network.bridge.enable_ip_masquerade"="true" \
      -o "com.docker.network.driver.mtu"="1500" kind || true

  echo "Configuring the 'kind' network with the docker registries"
  docker network connect kind ${DOCKERIO_CACHE_NAME} 2>/dev/null || true
  docker network connect kind ${QUAYIO_CACHE_NAME} 2>/dev/null || true
  docker network connect kind ${GCRIO_CACHE_NAME} 2>/dev/null || true
  docker network connect kind ${USDOCKERPKGDEV_CACHE_NAME} 2>/dev/null || true
}

function setup-host-network { #
  # ./macos-setup/25-network-setup.sh

  # REQS:
  # - Kind is running with MetalLB

  ##########
  # Host
  ##########

  #first delete any old route to 172.18
  sudo route -nv delete -net 172.18

  # show members of the bridge vnet
  ifconfig bridge100

  # get IP addr on the lima0 interface
  LIMA_IP_ADDR=$(limactl shell ${LIMA_INSTANCE} -- ip -o -4 a s | grep lima0 | grep -E -o 'inet [0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' | cut -d' ' -f2)
  echo $LIMA_IP_ADDR

  # add route to the Lima VM
  sudo route -nv add -net 172.18 ${LIMA_IP_ADDR}

  # check route
  route get 172.18.1.1
  #traceroute 172.18.1.1

  # delete route
  #sudo route -nv delete -net 172.18 ${LIMA_IP_ADDR}

  # ./macos-setup/05-prepare-mac-host.sh
  prepare-mac-host
}

function setup-lima-network { #
  # note: this is a script to run in the VM !!
  ${LIMA_BIN} -- sh ./lima/35-lima-to-kind-routing.sh
}

function config-network-end-to-end { #
  # depends: setup-kind-bridge setup-host-network setup-lima-network

  setup-kind-bridge
  setup-host-network
  setup-lima-network
}

function test { #
  kubectl run nginx --image nginx:1.22
  kubectl expose po/nginx --port 80 --type LoadBalancer
  kubectl get svc
  kubectl wait po --for condition=Ready --timeout 20s nginx
  curl --max-time 21 --connect-timeout 20 -I -v $(kubectl get svc nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
}

function clean-test { #
  kubectl delete svc nginx
  kubectl delete po nginx
}

function registries { #
  # depends: setup-kind-bridge
  # ./lima/17-docker-registries.sh
  mkdir -p ${KIND_HOST_HOME_DIR}

  # DOCKER IMAGE CACHES ("registry v2" or "distribution:2.8.1")
  registry_img_loaded=$(docker image ls --format '{{.Repository}}:{{.Tag}}' | grep "${REGISTRY_IMAGE_TAG}" | wc -l)
  if [ ${registry_img_loaded} -ne 1 ]; then
    echo "Loading the ${REGISTRY_IMAGE_TAG} image into the VM..."
    docker load < ${LIMA_DATA_DIR}/distribution-distribution-2.8.1.tar
  fi

  DOCKERIO_CACHE_PORT='5030'
  DOCKERIO_CACHE_RUNNING="$(docker inspect -f '{{.State.Running}}' "${DOCKERIO_CACHE_NAME}" 2>/dev/null || true)"
  QUAYIO_CACHE_PORT='5010'
  QUAYIO_CACHE_RUNNING="$(docker inspect -f '{{.State.Running}}' "${QUAYIO_CACHE_NAME}" 2>/dev/null || true)"
  GCRIO_CACHE_PORT='5020'
  GCRIO_CACHE_RUNNING="$(docker inspect -f '{{.State.Running}}' "${GCRIO_CACHE_NAME}" 2>/dev/null || true)"
  USDOCKERPKGDEV_CACHE_PORT='5040'
  USDOCKERPKGDEV_CACHE_RUNNING="$(docker inspect -f '{{.State.Running}}' "${USDOCKERPKGDEV_CACHE_NAME}" 2>/dev/null || true)"

  # clean stopped containers
  if [ "${DOCKERIO_CACHE_RUNNING}" = "false" ]; then
    echo "Removing stopped container ${DOCKERIO_CACHE_NAME}"
    docker rm -f "${DOCKERIO_CACHE_NAME}" 2>/dev/null || true
  fi
  if [ "${QUAYIO_CACHE_RUNNING}" = "false" ]; then
    echo "Removing stopped container ${QUAYIO_CACHE_NAME}"
    docker rm -f "${QUAYIO_CACHE_NAME}" 2>/dev/null || true
  fi
  if [ "${GCRIO_CACHE_RUNNING}" = "false" ]; then
    echo "Removing stopped container ${GCRIO_CACHE_NAME}"
    docker rm -f "${GCRIO_CACHE_NAME}" 2>/dev/null || true
  fi
  if [ "${USDOCKERPKGDEV_CACHE_RUNNING}" = "false" ]; then
    echo "Removing stopped container ${USDOCKERPKGDEV_CACHE_NAME}"
    docker rm -f "${USDOCKERPKGDEV_CACHE_NAME}" 2>/dev/null || true
  fi

  # docker.io mirror
  if [ -z "${DOCKERIO_CACHE_RUNNING}" -o "${DOCKERIO_CACHE_RUNNING}" = "false" ]; then
    cat > ${KIND_HOST_HOME_DIR}/dockerio-cache-config.yml <<EOF
version: 0.1
proxy:
  remoteurl: https://registry-1.docker.io
log:
  fields:
    service: registry
storage:
  cache:
    blobdescriptor: inmemory
  filesystem:
    rootdirectory: /var/lib/registry
http:
  addr: :${DOCKERIO_CACHE_PORT}
  headers:
    X-Content-Type-Options: [nosniff]
health:
  storagedriver:
    enabled: true
    interval: 10s
    threshold: 3
EOF
    echo "Starting docker.io mirror"
    docker run \
      -d --restart=always -v ${KIND_VM_HOME_DIR}/dockerio-cache-config.yml:/etc/docker/registry/config.yml -p ${DOCKERIO_CACHE_PORT}:${DOCKERIO_CACHE_PORT} \
      -v ${DOCKERIO_CACHE_DIR}:/var/lib/registry --name "${DOCKERIO_CACHE_NAME}" "${REGISTRY_IMAGE_TAG}"
  fi
  # quay.io mirror
  if [ -z "${QUAYIO_CACHE_RUNNING}" -o "${QUAYIO_CACHE_RUNNING}" = "false" ]; then
    cat > ${KIND_HOST_HOME_DIR}/quayio-cache-config.yml <<EOF
version: 0.1
proxy:
  remoteurl: https://quay.io
log:
  fields:
    service: registry
storage:
  cache:
    blobdescriptor: inmemory
  filesystem:
    rootdirectory: /var/lib/registry
http:
  addr: :${QUAYIO_CACHE_PORT}
  headers:
    X-Content-Type-Options: [nosniff]
health:
  storagedriver:
    enabled: true
    interval: 10s
    threshold: 3
EOF
    echo "Starting quay.io mirror"
    docker run \
      -d --restart=always -v ${KIND_VM_HOME_DIR}/quayio-cache-config.yml:/etc/docker/registry/config.yml -p ${QUAYIO_CACHE_PORT}:${QUAYIO_CACHE_PORT} \
      -v ${QUAYIO_CACHE_DIR}:/var/lib/registry --name "${QUAYIO_CACHE_NAME}" "${REGISTRY_IMAGE_TAG}"
  fi
  # gcr.io mirror
  if [ -z "${GCRIO_CACHE_RUNNING}" -o "${GCRIO_CACHE_RUNNING}" = "false" ]; then
    cat > ${KIND_HOST_HOME_DIR}/gcrio-cache-config.yml <<EOF
version: 0.1
proxy:
  remoteurl: https://gcr.io
log:
  fields:
    service: registry
storage:
  cache:
    blobdescriptor: inmemory
  filesystem:
    rootdirectory: /var/lib/registry
http:
  addr: :${GCRIO_CACHE_PORT}
  headers:
    X-Content-Type-Options: [nosniff]
health:
  storagedriver:
    enabled: true
    interval: 10s
    threshold: 3
EOF
    echo "Starting gcr.io mirror"
    docker run \
      -d --restart=always -v ${KIND_VM_HOME_DIR}/gcrio-cache-config.yml:/etc/docker/registry/config.yml -p ${GCRIO_CACHE_PORT}:${GCRIO_CACHE_PORT} \
      -v ${GCRIO_CACHE_DIR}:/var/lib/registry --name "${GCRIO_CACHE_NAME}" "${REGISTRY_IMAGE_TAG}"
  fi
  # us-docker.pkg.dev mirror
  if [ -z "${USDOCKERPKGDEV_CACHE_RUNNING}" -o "${USDOCKERPKGDEV_CACHE_RUNNING}" = "false" ]; then
    cat > ${KIND_HOST_HOME_DIR}/us-docker.pkg.dev-cache-config.yml <<EOF
version: 0.1
proxy:
  remoteurl: https://us-docker.pkg.dev
log:
  fields:
    service: registry
storage:
  cache:
    blobdescriptor: inmemory
  filesystem:
    rootdirectory: /var/lib/registry
http:
  addr: :${USDOCKERPKGDEV_CACHE_PORT}
  headers:
    X-Content-Type-Options: [nosniff]
health:
  storagedriver:
    enabled: true
    interval: 10s
    threshold: 3
EOF
    echo "Starting us-docker.pkg.dev mirror"
    docker run \
      -d --restart=always -v ${KIND_VM_HOME_DIR}/us-docker.pkg.dev-cache-config.yml:/etc/docker/registry/config.yml -p ${USDOCKERPKGDEV_CACHE_PORT}:${USDOCKERPKGDEV_CACHE_PORT} \
      -v ${USDOCKERPKGDEV_CACHE_DIR}:/var/lib/registry --name "${USDOCKERPKGDEV_CACHE_NAME}" ${REGISTRY_IMAGE_TAG} 
  fi

  # NETWORK SETUP FOR DOCKER REGISTRIES
  echo "Setting up the network for the docker registries"
  docker network connect kind ${DOCKERIO_CACHE_NAME} 2>/dev/null || true
  docker network connect kind ${QUAYIO_CACHE_NAME} 2>/dev/null || true
  docker network connect kind ${GCRIO_CACHE_NAME} 2>/dev/null || true
  docker network connect kind ${USDOCKERPKGDEV_CACHE_NAME} 2>/dev/null || true
}

function registries-stop { #
  # ./lima/18-stop-docker-registries.sh

  docker stop "${USDOCKERPKGDEV_CACHE_NAME}"
  docker stop "${GCRIO_CACHE_NAME}"
  docker stop "${QUAYIO_CACHE_NAME}"
  docker stop "${DOCKERIO_CACHE_NAME}"
}

function prepare-mac-host { #
  # ./macos-setup/05-prepare-mac-host.sh

  # docker work dir and cache dirs
  sudo mkdir -p ${LIMA_DATA_DIR}
  sudo chown $(whoami) ${LIMA_DATA_DIR}
  sudo mkdir -p ${GCRIO_CACHE_DIR} ${QUAYIO_CACHE_DIR} ${DOCKERIO_CACHE_DIR} ${USDOCKERPKGDEV_CACHE_DIR}

  # pull and save images
  for img in \
      distribution/distribution:2.8.1 \
      quay.io/metallb/controller:v0.11.0 \
      quay.io/metallb/speaker:v0.11.0
  do
    # replace forward slashes and colon by hyphens
    s=${img//\//-}
    TAR=${LIMA_DATA_DIR}/${s/:/-}.tar
    if [[ ! -f $TAR ]]; then
      docker pull $img
      docker save $img > $TAR
    fi
  done

  # the img-tar xform for the kindest/node image is different ...
  TAR="${LIMA_DATA_DIR}/kind-${KIND_NODE_VERSION}-image.tar"
  if [[ ! -f $TAR ]]; then
    img="kindest/node:${KIND_NODE_VERSION}"
    docker pull $img
    docker save $img > $TAR
  fi
}
